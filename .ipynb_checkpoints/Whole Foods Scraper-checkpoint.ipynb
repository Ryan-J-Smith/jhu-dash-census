{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Tutorial - Whole Foods\n",
    "\n",
    "We keep using Whole Foods (WF) as an example of looking up average demographics.  To find the average demographic for Whole Foods, we need to find where the WF stores are located.  In the absence of a list of store locations, we may need to venture forth onto the web to get one ourselves.  We may need to scrape.\n",
    "\n",
    "Scraping is essentially the process of automatically gathering text or data from a web page.  Depending on the site, this can be very easy or very difficult.\n",
    "\n",
    "In the case of WF, their store location page looks plain enough (http://www.wholefoodsmarket.com/stores/list/state)\n",
    "\n",
    "**Note: If you are using anaconda, you probably have all the required packages.  If not, you will need to `pip install`: `requests`, `beautifulsoup4`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests # Used for getting HTML\n",
    "from bs4 import BeautifulSoup # Used for parsing HTML\n",
    "\n",
    "BASE_URL = \"http://www.wholefoodsmarket.com/stores/list/state\"\n",
    "PAGE_URL = \"http://www.wholefoodsmarket.com/stores/list/state?field_postal_address_administrative_area=&page=1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a single URL\n",
    "\n",
    "Here we will simply request one page and look at the response that we get back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "response = requests.get(PAGE_URL)\n",
    "#print response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the plain html from the page.  If we look through carefully, we can see some things that look like an address.  Ideally we want to extract each of those addresses into a convenient data structure.  In short we want to parse this html into somehting useful.\n",
    "\n",
    "Conveniently, this html seems to be very well structured.  We can see that the tags seem to be well organized.  There are tags such as:\n",
    "\n",
    "`<div class=\"views-field views-field-field-postal-address\">`\n",
    "\n",
    "`<div class=\"throughfare\">450 Rhode Island St</div>`\n",
    "\n",
    "`<span class=\"locality\">San Francisco</span>`\n",
    "\n",
    "`<span class=\"state\">CA</span>`\n",
    "\n",
    "`<span class=\"postal-code\">94107</span>`\n",
    "\n",
    "One way of doing this is regular expressions, but those can often be difficult to work with. Instead we can use `Beautiful Soup` which is designed with this task in mind. In the following section we will input the HTML into BeautifulSoup and use a pretty printing feature to get a better view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text)\n",
    "# print soup.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the information we want is within a div tag called `\"view-field views-field-field-postal-address\"`.  We will ask BeautifulSoup to find the first example of this tag and return everything inside it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"views-field views-field-field-postal-address\"> <div class=\"field-content\"><div class=\"street-block\"><div class=\"thoroughfare\">7881 Edinger Ave Suite 150</div></div><div class=\"addressfield-container-inline locality-block country-US\"><span class=\"locality\">Huntington Beach</span>, <span class=\"state\">CA</span> <span class=\"postal-code\">92647</span></div><span class=\"country\">United States</span></div> </div>\n"
     ]
    }
   ],
   "source": [
    "address_class = \"views-field views-field-field-postal-address\"\n",
    "parent_div = soup.find('div', attrs={'class': address_class}) #Find (at most) *one*\n",
    "print parent_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep, that looks like all the info we need for an address, so now we will parse out the remaining components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': u'Huntington Beach', 'state': u'CA', 'street': u'7881 Edinger Ave Suite 150', 'zip code': u'92647'}\n",
      "<div class=\"thoroughfare\">7881 Edinger Ave Suite 150</div>\n"
     ]
    }
   ],
   "source": [
    "street_class = \"thoroughfare\"\n",
    "city_class = \"locality\"\n",
    "state_class = \"state\"\n",
    "zip_class = \"postal-code\"\n",
    "\n",
    "address = {}\n",
    "\n",
    "street = parent_div.find(\"div\", street_class)\n",
    "address[\"street\"] = street.text\n",
    "\n",
    "city = parent_div.find(\"span\", city_class)\n",
    "address[\"city\"] = city.text\n",
    "\n",
    "state = parent_div.find(\"span\", state_class)\n",
    "address[\"state\"] = state.text\n",
    "\n",
    "zip_code = parent_div.find(\"span\", zip_class)\n",
    "address[\"zip code\"] = zip_code.text\n",
    "\n",
    "print address\n",
    "print street"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, that gives us one address.  Now we just have to do this and loop over all the elements in the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'city': u'Huntington Beach', 'state': u'CA', 'street': u'7881 Edinger Ave Suite 150', 'zip code': u'92647'}\n",
      "{'city': u'San Ramon', 'state': u'CA', 'street': u'100 Sunset Drive', 'zip code': u'94583'}\n",
      "{'city': u'Walnut Creek', 'state': u'CA', 'street': u'1333 Newell Ave', 'zip code': u'94596'}\n",
      "{'city': u'Davis', 'state': u'CA', 'street': u'500 First Street', 'zip code': u'95616'}\n",
      "{'city': u'San Francisco', 'state': u'CA', 'street': u'450 Rhode Island St', 'zip code': u'94107'}\n",
      "{'city': u'Dublin', 'state': u'CA', 'street': u'5200 Dublin Blvd.', 'zip code': u'94568'}\n",
      "{'city': u'Mill Valley', 'state': u'CA', 'street': u'731 East Blithedale', 'zip code': u'94941'}\n",
      "{'city': u'Los Angeles', 'state': u'CA', 'street': u'6350 West 3rd Street', 'zip code': u'90036'}\n",
      "{'city': u'San Mateo', 'state': u'CA', 'street': u'1010 Park Place', 'zip code': u'94403'}\n",
      "{'city': u'Santa Clarita', 'state': u'CA', 'street': u'24130 Valencia Blvd', 'zip code': u'91355'}\n",
      "{'city': u'Northridge', 'state': u'CA', 'street': u'19340 Rinaldi Street', 'zip code': u'91326'}\n",
      "{'city': u'Folsom', 'state': u'CA', 'street': u'270 Palladio Parkway', 'zip code': u'95630'}\n",
      "{'city': u'Sonoma', 'state': u'CA', 'street': u'Sonoma Marketplace', 'zip code': u'95476'}\n",
      "{'city': u'Venice', 'state': u'CA', 'street': u'225 Lincoln Blvd.', 'zip code': u'90291'}\n",
      "{'city': u'Playa Vista', 'state': u'CA', 'street': u'12746 W Jefferson Blvd', 'zip code': u'90094'}\n",
      "{'city': u'Pasadena', 'state': u'CA', 'street': u'3751 E. Foothill Blvd.', 'zip code': u'91107'}\n",
      "{'city': u'Santa Rosa', 'state': u'CA', 'street': u'390 Coddingtown Mall', 'zip code': u'95401'}\n",
      "{'city': u'Redwood City', 'state': u'CA', 'street': u'1250 Jefferson Ave', 'zip code': u'94062'}\n",
      "{'city': u'Newport Beach', 'state': u'CA', 'street': u'415 Newport Center Drive', 'zip code': u'92660'}\n",
      "{'city': u'San Jose', 'state': u'CA', 'street': u'777 The Alameda', 'zip code': u'95126'}\n"
     ]
    }
   ],
   "source": [
    "address_list = []\n",
    "\n",
    "for store in soup.find_all(\"div\", address_class):\n",
    "    address = {}\n",
    "    \n",
    "    street = store.find(\"div\", street_class)\n",
    "    address[\"street\"] = street.text\n",
    "\n",
    "    city = store.find(\"span\", city_class)\n",
    "    address[\"city\"] = city.text\n",
    "\n",
    "    state = store.find(\"span\", state_class)\n",
    "    address[\"state\"] = state.text\n",
    "\n",
    "    zip_code = store.find(\"span\", zip_class)\n",
    "    address[\"zip code\"] = zip_code.text\n",
    "\n",
    "    print address\n",
    "    address_list.append(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next? All the URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PAGE_URL = \"http://www.wholefoodsmarket.com/stores/list/state?field_postal_address_administrative_area=&page=\"\n",
    "page_num = 1\n",
    "max_pages = 3\n",
    "\n",
    "address_class = \"views-field views-field-field-postal-address\"\n",
    "street_class = \"thoroughfare\"\n",
    "city_class = \"locality\"\n",
    "state_class = \"state\"\n",
    "zip_class = \"postal-code\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "address_list = []\n",
    "for page_num in range(1, max_pages + 1):\n",
    "    response = requests.get(PAGE_URL + str(page_num))\n",
    "    soup = BeautifulSoup(response.text)\n",
    "\n",
    "    for store in soup.find_all(\"div\", address_class):\n",
    "        address = {}\n",
    "\n",
    "        street = store.find(\"div\", street_class)\n",
    "        address[\"street\"] = street.text\n",
    "\n",
    "        city = store.find(\"span\", city_class)\n",
    "        address[\"city\"] = city.text\n",
    "\n",
    "        state = store.find(\"span\", state_class)\n",
    "        address[\"state\"] = state.text\n",
    "\n",
    "        zip_code = store.find(\"span\", zip_class)\n",
    "        address[\"zip code\"] = zip_code.text\n",
    "\n",
    "        address_list.append(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n"
     ]
    }
   ],
   "source": [
    "print len(address_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to CSV\n",
    "\n",
    "We could do this with pandas, but instead we'll implement a solution described on this [StackOverflow Post](http://stackoverflow.com/questions/3086973/how-do-i-convert-this-list-of-dictionaries-to-a-csv-file-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "toCSV = address_list\n",
    "keys = toCSV[0].keys()\n",
    "with open('./data/addresses.csv', 'wb') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(toCSV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
